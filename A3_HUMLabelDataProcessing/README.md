This directory contains code written to extract and pre-process human-listener labelled data used in this study. 

`A1_IdOverlapAndFilesWErrors.m` identifies overlaps in vocalisations based on onsets and offsets as determined by human listeners, and chops up overlapping vocalisations into overlapping and non-overlapping sub-vocalisations. Requires `DetectOverlap.m` and `GetNonOverlapVocs.m`. Schematics describing overlap processing are available in `OlpProcSchem.pptx` and `OlpProcSchem.pdf`. This script is executed on `.csv` files parsed from cleaned-up `.eaf` files. To keep the clean-up pipeline and the data processing pipeline separate, these `.csv` files (and the associated cleaned-up `.eaf` files, which may have undergone several rounds of automated and manual clean-ups as required) are copied into new folders within the human labelled data processing folder (see `Metadata_CodeAndFiles.xlsx` for details of data organisation).  

`A2_TSAcousticsBatchProcessHUMlabel.m` extracts time series info from each .its file. Requires `getPraatAcoustics.m`, `getAcousticsTS_HUMlabel.m`, and `getIndividualAudioSegmentsHUMlabel.m`. Note that a few files that come from different sub-recordings within the same daylong recording (identified by suffixes a, b, etc.) don't have a wave file match, because the wave files aren't necessarily split up into a, b, etc. While the script accounts for this, it is advisable to check for such exceptions and write additional code to deal with these exceptions (if they occur) or to do the time series processing manually for those files. Acoustics info is computed for vocalisations that have been chopped up into overlapping and non-overlapping sub-vocalisations wherever applicable. This script is not parallelised (unlike its LENA daylong counterpart) and takes about 3 hours to run. If you attempt to parallelise this script, note that you need to do such that multiple processes are not trying to access the same temporary text file Praat utilises. As this is set up, the temporary Praat text file is opened within each infant ID folder which contains all recordings for that infant. As such, parallelisation needs to be set up at the level of the infant ID folder and not at a lower level. 

`A3_AddAnnotationToTS_AndRemoveOLP.m` adds human-listener annotation tags (T, U, N for adult vocalisation; and R, X, C, L for infant vocalisations) back to the acoustics time series. This script also adds child speech-related (referred to as CHNSP in the code and ChSp in the Burstiness pre-print (2025) and paper) and child non-speech-related (referred to as CHNNSP in the code and ChNsp in the Burstiness pre-print (2025) and paper) speaker labels to infant utterances. Finally, this script removes sub-vocalisations (obtained from processing overlapping vocalisations in `A1_IdOverlapAndFilesWErrors.m`) that are tagged as overlaps.
 
`A4_MergeSubRecs_GetSectionNum.m` merges files from sub-recordings that are from the same daylong recording and assigns section numbers to each utterance. Further, this script:
-	flags files which have 5-minute sections that were marked in the coding spreadsheet for human listener annotation but were not annotated. This info is written into the table `FilesWithUnannotatedSections.csv`
-	flags files which have 5 minute sections that are less than 30 minutes apart (excluding 5-minute sections that are from different sub-recordings). This info is written into table `FilesWithLessThan30minBnSections.csv`

`A5_GetZscoredData_LENAandHumLabels.m` takes the acoustics (pitch, amplitude, duration) from the entire dataset (both LENA and human-listener labelled data), log transforms duration and mean pitch, z-scores the data, and saves the z-scored acoustics data and other time series data for both LENA and human-listener labelled data. Z-scoring is done wrt the combined LENA- and human-listener labelled data. Note that the z-scored LENA acoustics and duration data are *only* generated at this step. Also note that the Burstiness paper and pre-print (2025) does not present results based on acoustics or duration data (which are the z-scored variables). Nevertheless, this is part of the data processing pipeline and this code is presented here as part of the codebase. 

`A6_MatchingSectionsToCodingSheet.m` matches the human-listener annotated 5 minute sections to the corresponding 5 minute sections in the LENA-labelled data, and saves these data tables, to facilitate validation.

`A7_GetMetadataForValidationData.m` generates a metadata file (`ValDataMergedTSMetaDataTab.csv`) for the human listener-labelled data.

For more specific details, please read comments about paths and other notes in the files before executing them.
